{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this project is to predict if bitcoin price one day in the future will be higher or lower than current price based on the last 30 days using recurrent neural networks especially LSTM cells. I tried to use different features such as page views volume etc. The project is done 100% by my self but the model part is based on sentdex video of recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we just import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import talib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for Bitcoin price and volume is taken from cryptocompare.com and page views are based on wikipedia page views and seraching for Bitcoin topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Bitcoin\n",
      "Date               \n",
      "2015-07-01    12957\n",
      "2015-07-02     9802\n",
      "2015-07-03     8307\n",
      "2015-07-04     8947\n",
      "2015-07-05     8692\n",
      "...             ...\n",
      "2020-05-12    10677\n",
      "2020-05-13     8349\n",
      "2020-05-14     8061\n",
      "2020-05-15     7443\n",
      "2020-05-16     7142\n",
      "\n",
      "[1782 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_btc=pd.read_csv('BTC_USD_Coinbase_day_2020-05-17.csv',index_col='datetime')\n",
    "page_views=pd.read_csv('pageviews-20150701-20200516.csv',index_col='Date')\n",
    "print(page_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining two data frames in to one and creating new features rsi(relative strength index), mean and standard deviation and the future price which is current price moved by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD   future  BTC_Volume    views        rsi          std  \\\n",
      "2015-07-01   257.97   255.22     8150.38  12957.0  63.516932    11.714312   \n",
      "2015-07-02   255.22   256.36     6288.44   9802.0  60.149131    11.729520   \n",
      "2015-07-03   256.36   260.72     4850.58   8307.0  61.070622    11.719544   \n",
      "2015-07-04   260.72   271.15     4119.09   8947.0  64.455850    11.753758   \n",
      "2015-07-05   271.15   270.41     7902.94   8692.0  70.961211    12.366152   \n",
      "...             ...      ...         ...      ...        ...          ...   \n",
      "2020-05-12  8821.42  9321.26    19825.54  10677.0  56.001358  1008.175343   \n",
      "2020-05-13  9321.26  9795.34    20859.19   8349.0  61.535348  1006.165262   \n",
      "2020-05-14  9795.34  9312.10    27425.67   8061.0  65.914358  1019.242768   \n",
      "2020-05-15  9312.10  9383.16    22369.96   7443.0  58.592039   988.772268   \n",
      "2020-05-16  9383.16  9761.46    10642.35   7142.0  59.307895   978.191598   \n",
      "\n",
      "                   mean  \n",
      "2015-07-01   239.563000  \n",
      "2015-07-02   240.562000  \n",
      "2015-07-03   241.588333  \n",
      "2015-07-04   242.802000  \n",
      "2015-07-05   244.329333  \n",
      "...                 ...  \n",
      "2020-05-12  8074.099667  \n",
      "2020-05-13  8156.101333  \n",
      "2020-05-14  8253.367000  \n",
      "2020-05-15  8342.966333  \n",
      "2020-05-16  8418.650333  \n",
      "\n",
      "[1782 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'BTC-USD': df_btc.close,\n",
    "                   'BTC_Volume': df_btc.volumefrom,\n",
    "                   'views': page_views.Bitcoin\n",
    "                   })\n",
    "df['future']=df['BTC-USD'].shift(-1)\n",
    "df['rsi'] = talib.RSI(df['BTC-USD'].values, timeperiod=14)\n",
    "df['std']=df['BTC-USD'].rolling(window=30).std()\n",
    "df['mean']=df['BTC-USD'].rolling(window=30).mean()\n",
    "df=df[['BTC-USD','future','BTC_Volume','views','rsi','std','mean']]\n",
    "df=df.dropna()\n",
    "df.replace(0,np.nan, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am creating my target future which results 1 if future price is higher than current(which means worth buying) and 0 if future price is smaller than current(which isn't worth to buy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current,future):\n",
    "    if float(future)>float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply function to our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD  BTC_Volume   future    views        rsi          std  \\\n",
      "2015-07-01   257.97     8150.38   255.22  12957.0  63.516932    11.714312   \n",
      "2015-07-02   255.22     6288.44   256.36   9802.0  60.149131    11.729520   \n",
      "2015-07-03   256.36     4850.58   260.72   8307.0  61.070622    11.719544   \n",
      "2015-07-04   260.72     4119.09   271.15   8947.0  64.455850    11.753758   \n",
      "2015-07-05   271.15     7902.94   270.41   8692.0  70.961211    12.366152   \n",
      "...             ...         ...      ...      ...        ...          ...   \n",
      "2020-05-12  8821.42    19825.54  9321.26  10677.0  56.001358  1008.175343   \n",
      "2020-05-13  9321.26    20859.19  9795.34   8349.0  61.535348  1006.165262   \n",
      "2020-05-14  9795.34    27425.67  9312.10   8061.0  65.914358  1019.242768   \n",
      "2020-05-15  9312.10    22369.96  9383.16   7443.0  58.592039   988.772268   \n",
      "2020-05-16  9383.16    10642.35  9761.46   7142.0  59.307895   978.191598   \n",
      "\n",
      "                   mean  target  \n",
      "2015-07-01   239.563000       0  \n",
      "2015-07-02   240.562000       1  \n",
      "2015-07-03   241.588333       1  \n",
      "2015-07-04   242.802000       1  \n",
      "2015-07-05   244.329333       0  \n",
      "...                 ...     ...  \n",
      "2020-05-12  8074.099667       1  \n",
      "2020-05-13  8156.101333       1  \n",
      "2020-05-14  8253.367000       0  \n",
      "2020-05-15  8342.966333       1  \n",
      "2020-05-16  8418.650333       1  \n",
      "\n",
      "[1782 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df['target'] = list(map(classify, df['BTC-USD'], df['future']))\n",
    "\n",
    "df=df[['BTC-USD','BTC_Volume','future','views','rsi','std','mean','target']]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part as I mentioned before is based on sentdex youtube video. Here I set different parameters like:\n",
    "SEQ_LEN- which is the numer of day we try to predict our future price\n",
    "FUTURE_PERIOD_PREDICT- number of days in the future that we trying to predict\n",
    "EPOCHS-how many time our model is going throught data\n",
    "BATCH_SIZE-number of training examples utilized in one iteration\n",
    "and then I want to change all the values to percentage changes, because different features values differ from each other significantly.\n",
    "Secondly I want to normalize all the data beetwen 0 and 1, I don't want  some values to have bigger impact on our model than the others.\n",
    "Then I want to shuffle the data to make sure that model is trying to find some pattern not memorize all the data, and finally make sure that I have equal number of buys and sell, which also help to not influencing the model in any direction and transforming all the data from pandas data frame to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN=30\n",
    "FUTURE_PERIOD_PREDICT=1\n",
    "EPOCHS = 15  \n",
    "BATCH_SIZE = 64 \n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  \n",
    "\n",
    "def preprocess_df(df_1):\n",
    "    df_1 = df_1.drop(\"future\", 1)  \n",
    "\n",
    "    for col in df_1.columns:  \n",
    "        if col != \"target\":  \n",
    "            df_1[col] = df_1[col].pct_change()  \n",
    "            df_1.dropna(inplace=True)  \n",
    "            df_1[col] = preprocessing.scale(df_1[col].values)  \n",
    "\n",
    "    df_1.dropna(inplace=True)  \n",
    "\n",
    "\n",
    "    sequential_data = []  \n",
    "    prev_days = deque(maxlen=SEQ_LEN)  \n",
    "\n",
    "    for i in df_1.values:  \n",
    "        prev_days.append([n for n in i[:-1]])  \n",
    "        if len(prev_days) == SEQ_LEN:  \n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  \n",
    "\n",
    "    random.shuffle(sequential_data)  \n",
    "\n",
    "    buys = []  \n",
    "    sells = []  \n",
    "\n",
    "    for seq, target in sequential_data:  \n",
    "        if target == 0: \n",
    "            sells.append([seq, target]) \n",
    "        elif target == 1:  \n",
    "            buys.append([seq, target])  \n",
    "\n",
    "    random.shuffle(buys)  \n",
    "    random.shuffle(sells) \n",
    "\n",
    "    lower = min(len(buys), len(sells))  \n",
    "\n",
    "    buys = buys[:lower]  \n",
    "    sells = sells[:lower]  \n",
    "\n",
    "    sequential_data = buys+sells  \n",
    "    random.shuffle(sequential_data) \n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data: \n",
    "        X.append(seq)  \n",
    "        y.append(target)  \n",
    "\n",
    "    return np.array(X), y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I set up validation df, which are data that the model didn't see(our test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-21\n"
     ]
    }
   ],
   "source": [
    "times = sorted(df.index.values)\n",
    "last_10pct = sorted(df.index.values)[-int(0.1*len(times))]\n",
    "print(last_10pct)\n",
    "\n",
    "validation_df = df[(df.index >= last_10pct)] \n",
    "df = df[(df.index < last_10pct)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using my function to process all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 1424 validation: 128\n",
      "Dont buys: 712, buys: 712\n",
      "VALIDATION Dont buys: 64, buys: 64\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = preprocess_df(df)\n",
    "validation_x, validation_y = preprocess_df(validation_df)\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "validation_x = np.asarray(validation_x)\n",
    "validation_y = np.asarray(validation_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model by it's self which as I mentioned before is based on sentdex video.\n",
    " The first parameter in LSTM and Dense are number of cells. Dropout means percentage of data that we randomly throw away to prevent overfitting. Relu as activation function which adds nonlinearity to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1424 samples, validate on 128 samples\n",
      "Epoch 1/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.9482 - accuracy: 0.4964WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 9s 6ms/sample - loss: 0.9512 - accuracy: 0.4958 - val_loss: 0.6906 - val_accuracy: 0.5078\n",
      "Epoch 2/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7880 - accuracy: 0.5163WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7879 - accuracy: 0.5169 - val_loss: 0.6893 - val_accuracy: 0.5312\n",
      "Epoch 3/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7600 - accuracy: 0.5270WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7615 - accuracy: 0.5246 - val_loss: 0.6945 - val_accuracy: 0.5078\n",
      "Epoch 4/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7405 - accuracy: 0.5384WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7424 - accuracy: 0.5393 - val_loss: 0.6929 - val_accuracy: 0.4922\n",
      "Epoch 5/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7605 - accuracy: 0.5334WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7601 - accuracy: 0.5337 - val_loss: 0.6937 - val_accuracy: 0.5078\n",
      "Epoch 6/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7276 - accuracy: 0.5277WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7282 - accuracy: 0.5274 - val_loss: 0.6874 - val_accuracy: 0.5000\n",
      "Epoch 7/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7316 - accuracy: 0.5440WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7321 - accuracy: 0.5449 - val_loss: 0.6965 - val_accuracy: 0.5234\n",
      "Epoch 8/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7176 - accuracy: 0.5398WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7168 - accuracy: 0.5407 - val_loss: 0.7169 - val_accuracy: 0.5156\n",
      "Epoch 9/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7118 - accuracy: 0.5391WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7113 - accuracy: 0.5386 - val_loss: 0.6930 - val_accuracy: 0.5234\n",
      "Epoch 10/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7073 - accuracy: 0.5412WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7065 - accuracy: 0.5428 - val_loss: 0.7125 - val_accuracy: 0.4531\n",
      "Epoch 11/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7098 - accuracy: 0.5554WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7095 - accuracy: 0.5569 - val_loss: 0.6924 - val_accuracy: 0.5078\n",
      "Epoch 12/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.7020 - accuracy: 0.5462WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.7024 - accuracy: 0.5442 - val_loss: 0.6900 - val_accuracy: 0.5312\n",
      "Epoch 13/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.6854 - accuracy: 0.5604WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.6856 - accuracy: 0.5611 - val_loss: 0.7159 - val_accuracy: 0.4609\n",
      "Epoch 14/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.6920 - accuracy: 0.5440WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.6926 - accuracy: 0.5428 - val_loss: 0.7082 - val_accuracy: 0.5156\n",
      "Epoch 15/15\n",
      "1408/1424 [============================>.] - ETA: 0s - loss: 0.6920 - accuracy: 0.5533WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1424/1424 [==============================] - 3s 2ms/sample - loss: 0.6920 - accuracy: 0.5520 - val_loss: 0.6997 - val_accuracy: 0.5625\n",
      "Test loss: 0.6996703892946243\n",
      "Test accuracy: 0.5625\n",
      "INFO:tensorflow:Assets written to: models\\30-SEQ-1-PRED-1589742194\\assets\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\\\{}\".format(NAME))\n",
    "\n",
    "filepath = \"epoch_{epoch:02d}-val_accuracy_{val_accuracy:.3f}\"\n",
    "checkpoint = ModelCheckpoint(\"models\\\\{}_{}.model\".format(NAME,filepath), monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[tensorboard, checkpoint],\n",
    ")\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save model\n",
    "model.save(\"models\\\\{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We get test accuracy on the level of 0.5625 which means our model predict right future price in 56,25% cases which is better than 50% but still not the best I think what could help this model is bigger number of data but I couldn't find bigger data sets with trend views for bitcion of course I can change some parameters to ensure better model performance or add more important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
